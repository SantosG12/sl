# -*- coding: utf-8 -*-
"""RegreionLogisticaYknn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1co2UkJ-WwV5lnxeSoHk9I-9IgoYMsEtn

#MODELO REGRESION LOGISTICA Y KNN
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Importar las librerías"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df_data = pd.read_pickle('/content/drive/MyDrive/Proyecto_sobre enfermedades cardiovasculares_DATA.T/DATASET/ddf_cardio_data_fin_EDA.pickle')

df_data.head()

df_cat = df_data.select_dtypes(exclude='number').copy()
df_cat = df_cat.drop(columns=['categoria_de_presión_arterial','BMI_category'])
df_num = df_data.select_dtypes(include='number').copy()
df_num = df_num.drop(columns=['numeric_cardio'])
df_data = pd.concat([df_cat,df_num],axis=1).copy()

# Convertir booleanos
df_data['Problema_CardioVascular'] = df_data['Problema_CardioVascular'].replace({True: 1, False: 0}).astype('int64')
df_data['Genero'] = df_data['Genero'].replace({1: 'Female', 2: 'Male'}).astype('object')
df_data['Fuma'] = df_data['Fuma'].replace({True: '1', False: '0'}).astype('object')
df_data['Toma_alchol'] = df_data['Toma_alchol'].replace({True: '1', False: '0'}).astype('object')
df_data['Actividad_fisica'] = df_data['Actividad_fisica'].replace({True: '1', False: '0'}).astype('object')

df_data.head()

#tipo de datos para saber
df_data.dtypes

"""##Dividir X e Y

"""

X = df_data.drop(columns='Problema_CardioVascular')
y = df_data['Problema_CardioVascular']

from sklearn.model_selection import train_test_split

X_trainval_orig, X_test_orig, y_trainval, y_test = train_test_split( X, y, test_size = 0.20, random_state = 42)

X_train_orig, X_val_orig, y_train, y_val = train_test_split( X_trainval_orig, y_trainval, test_size = 0.20, random_state = 42)

X_trainval_orig.shape

X_train_orig.shape

X_val_orig.shape

X_test_orig.shape

"""##Trasformando"""

from sklearn.preprocessing import OneHotEncoder
columnasOHE = ['Genero']
oneHE = OneHotEncoder(sparse_output = False, drop='first', dtype='int64', handle_unknown='ignore')

from sklearn.preprocessing import OrdinalEncoder
columnasOE = ['Colesterol','Glucosa', 'Fuma','Toma_alchol','Actividad_fisica']
categorias_Colesterol = ['1','2','3']
categorias_Glucosa = ['1','2','3']
categorias_Fuma = ['0','1']
categorias_Toma_alchol = ['0','1']
categorias_Actividad_fisica = ['0','1']
ordinalEN = OrdinalEncoder(categories=[categorias_Colesterol,categorias_Glucosa,categorias_Fuma,categorias_Toma_alchol,
                           categorias_Actividad_fisica], handle_unknown='use_encoded_value', unknown_value=9)

from sklearn.preprocessing import MinMaxScaler
columnasMMS = ['Edad','Altura','Peso','Presion_arterial_sistolica','Presion_arterial_diastolica','Bmi']
encoderMMS = MinMaxScaler()

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import FunctionTransformer

preprocessor = ColumnTransformer(
    transformers=[
        ("OneHotEncoder", oneHE, columnasOHE),
        ("OrdinalEncoder", ordinalEN, columnasOE),
        ("MinMaxScaler", encoderMMS, columnasMMS)
    ]
)

X_train = preprocessor.fit_transform(X_train_orig)
X_val = preprocessor.transform(X_val_orig)
X_trainval = preprocessor.transform(X_trainval_orig)
X_test = preprocessor.transform(X_test_orig)

print(X_train.shape, X_val.shape, X_trainval.shape, X_test.shape)

"""#Hiperparámetros para Regresión Logística


"""

# Definir la cuadrícula de hiperparámetros para Regresión Logística
param_grid_logreg = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Rango de valores para la regularización
    'solver': ['liblinear', 'lbfgs', 'saga'],  # Solvers compatibles
    'penalty': ['l2'],  # L2 es compatible con 'lbfgs' y 'liblinear'
    'max_iter': [100, 200, 500]  # Número de iteraciones
}

"""#Hiperparámetros para (KNN)"""

# Hiperparámetros ajustados para KNN
param_grid_knn = {
    'n_neighbors': [5, 10, 15, 20],  # Valores razonables de vecinos
    'weights': ['uniform', 'distance'],  # Mantener los dos tipos de ponderación
    'metric': ['euclidean', 'manhattan'],  # Limitar a dos métricas de distancia comunes
    'p': [1]  # Solo usa `p=1` (Manhattan) para `metric='minkowski'`
}

"""#Entrena, aplicando CV con hiperparametros de cada algoritmo RandomizedSearchCV

"""

from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

# Configuración de validación cruzada
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

"""#Regresión logística"""

logreg = LogisticRegression()
random_search_logreg = RandomizedSearchCV(
    estimator=logreg,
    param_distributions=param_grid_logreg,
    n_iter=10,
    cv=cv,
    scoring='precision',  # Métrica principal
    random_state=42,
    verbose=1
)
# Ajustar el modelo de Regresión Logística
random_search_logreg.fit(X_train, y_train)

from sklearn.metrics import precision_score
# Guardar el mejor modelo de Regresión Logística
best_model_logreg = random_search_logreg.best_estimator_

# Evaluación del modelo de Regresión Logística en el conjunto de entrenamiento
print("\nReporte de clasificación en Entrenamiento para Regresión Logística:")
y_train_pred_logreg = best_model_logreg.predict(X_train)  # Predicción de clases
print(classification_report(y_train, y_train_pred_logreg))  # Reporte detallado

# Calcular y mostrar la precisión
precision_train_logreg = precision_score(y_train, y_train_pred_logreg)
print(f"Precisión (Precision) de Regresión Logística en Entrenamiento: {precision_train_logreg:.4f}")

"""#(KNN)

"""

# Modelo: KNN
knn = KNeighborsClassifier()
random_search_knn = RandomizedSearchCV(
    estimator=knn,
    param_distributions=param_grid_knn,
    n_iter=10,
    cv=cv,
    scoring='precision',  # Métrica principal
    random_state=42,
    verbose=1
)
# Ajustar el modelo de KNN
random_search_knn.fit(X_train, y_train)

# Guardar el mejor modelo de KNN
best_model_knn = random_search_knn.best_estimator_

# Evaluación del modelo KNN en el conjunto de entrenamiento
print("\nReporte de clasificación en Entrenamiento para KNN:")
y_train_pred_knn = best_model_knn.predict(X_train)  # Predicción de clases
print(classification_report(y_train, y_train_pred_knn))  # Reporte detallado

# Calcular y mostrar la precisión
precision_train_knn = precision_score(y_train, y_train_pred_knn)
print(f"Precisión (Precision) de KNN en Entrenamiento: {precision_train_knn:.4f}")

"""# Evalúa los resultados con el conjunto de validación (el cual no está balanceado)

"""

from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score
import pandas as pd

# Usar el modelo guardado para validación
print("\nReporte de clasificación en Validación para Regresión Logística:")
y_val_pred_logreg = best_model_logreg.predict(X_val)  # Predicción de clases en validación
print(classification_report(y_val, y_val_pred_logreg))  # Reporte detallado

# Calcular la precisión específicamente
precision_val_logreg = precision_score(y_val, y_val_pred_logreg)
print(f"Precisión (Precision) de Regresión Logística en Validación: {precision_val_logreg:.4f}")

print("\nReporte de clasificación en Validación para KNN:")
y_val_pred_knn = best_model_knn.predict(X_val)  # Predicción de clases en validación
print(classification_report(y_val, y_val_pred_knn))  # Reporte detallado

# Calcular la precisión específicamente
precision_val_knn = precision_score(y_val, y_val_pred_knn)
print(f"Precisión (Precision) de KNN en Validación: {precision_val_knn:.4f}")

"""#Selecciona el mejor modelo con los mejores hiperparametros

Con base en los resultados del conjunto de validación, el modelo seleccionado será la Regresión Logística, sustentado en los siguientes puntos clave:

1. Precisión como Métrica Clave
La precisión es prioritaria para minimizar falsos positivos en escenarios críticos. La Regresión Logística obtuvo una precisión de 0.7661 en la clase positiva, superando los 0.7530 de KNN. Además, la precisión ponderada también fue superior (0.73 vs. 0.72), evidenciando su consistencia en ambas clases.

2. Equilibrio entre Precisión y Recall
La Regresión Logística logró un mejor balance con un recall de 0.68 frente al 0.66 de KNN, indicando que identifica una mayor proporción de casos positivos reales sin comprometer su precisión.

3. Simplicidad y Generalización
Como modelo lineal, la Regresión Logística es menos sensible a variaciones en los datos y tiene una alta capacidad de generalización, a diferencia de KNN, que puede ser afectado por la distribución de los datos.

4. Desempeño en Validación Real
En el conjunto de validación no balanceado, la Regresión Logística mostró métricas más consistentes y robustas, reforzando su capacidad para predecir en escenarios reales.

Conclusión
La Regresión Logística es la opción más adecuada, al maximizar la precisión y mantener un buen balance con el recall, lo que garantiza predicciones más confiables y una mejor toma de decisiones en escenarios críticos.

#Entrena el modelo ganador con los mejores hiperparametros usando todo xtrain + xvalid
"""

import numpy as np
# Combinar conjuntos de entrenamiento y validación
X_trainval = np.vstack([X_train, X_val])
y_trainval = np.hstack([y_train, y_val])

from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, roc_auc_score
# Predicción en TrainVal
print("\nReporte de Clasificación en TrainVal para Regresión Logística:")
y_trainval_pred_logreg = best_model_logreg.predict(X_trainval)  # Predicción de clases
y_trainval_proba_logreg = best_model_logreg.predict_proba(X_trainval)[:, 1]  # Probabilidades

# Reporte detallado
print(classification_report(y_trainval, y_trainval_pred_logreg))

# Calcular métricas clave
precision_trainval_logreg = precision_score(y_trainval, y_trainval_pred_logreg)
recall_trainval_logreg = recall_score(y_trainval, y_trainval_pred_logreg)
f1_trainval_logreg = f1_score(y_trainval, y_trainval_pred_logreg)
roc_auc_trainval_logreg = roc_auc_score(y_trainval, y_trainval_proba_logreg)

print(f"\nMétricas en TrainVal (Regresión Logística):")
print(f"Precisión (Precision): {precision_trainval_logreg:.4f}")
print(f"Recall: {recall_trainval_logreg:.2f}")
print(f"F1-Score: {f1_trainval_logreg:.2f}")
print(f"ROC-AUC: {roc_auc_trainval_logreg:.2f}")

"""#Evaluación el resultado con TEST"""

# Predicción en el conjunto de prueba
print("\nReporte de Clasificación Final en Prueba para Regresión Logística:")
y_test_pred_logreg = best_model_logreg.predict(X_test)  # Predicción de clases
print(classification_report(y_test, y_test_pred_logreg))  # Reporte detallado

# Calcular métricas clave
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score

y_test_proba_logreg = best_model_logreg.predict_proba(X_test)[:, 1]  # Probabilidades para ROC-AUC

precision_test_logreg = precision_score(y_test, y_test_pred_logreg)
recall_test_logreg = recall_score(y_test, y_test_pred_logreg)
f1_test_logreg = f1_score(y_test, y_test_pred_logreg)
roc_auc_test_logreg = roc_auc_score(y_test, y_test_proba_logreg)

print("\nMétricas en el Conjunto de Prueba:")
print(f"Precisión (Precision): {precision_test_logreg:.4f}")
print(f"Recall: {recall_test_logreg:.2f}")
print(f"F1-Score: {f1_test_logreg:.2f}")
print(f"ROC-AUC: {roc_auc_test_logreg:.2f}")

from sklearn.metrics import confusion_matrix
# Calcular la matriz de confusión
confusion_matrix_logreg = confusion_matrix(y_test, y_test_pred_logreg)

# Crear un DataFrame para la matriz de confusión
confusion_matrix_df = pd.DataFrame(
    confusion_matrix_logreg,
    columns=['Predicción NO', 'Predicción SI'],
    index=['Real NO', 'Real SI']
)

# Mostrar la matriz de confusión como DataFrame
print("\nMatriz de Confusión del Modelo Ganador:")
print(confusion_matrix_df)

# Generar la curva ROC
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

fpr_logreg, tpr_logreg, _ = roc_curve(y_test, y_test_proba_logreg)

# Graficar la curva ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr_logreg, tpr_logreg, label=f"Regresión Logística (AUC = {roc_auc_test_logreg:.2f})")
plt.plot([0, 1], [0, 1], 'k--', label="Azar (AUC = 0.50)")
plt.xlabel('Tasa de Falsos Positivos (FPR)')
plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
plt.title('Curva ROC - Modelo Ganador (Regresión Logística)')
plt.legend()
plt.grid()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Calcular la matriz de confusión
confusion_matrix_logreg = confusion_matrix(y_test, y_test_pred_logreg)

# Crear el heatmap de la matriz de confusión
plt.figure(figsize=(6, 4))  # Tamaño de la figura
sns.heatmap(
    confusion_matrix_logreg,
    annot=True,  # Mostrar los valores en las celdas
    fmt='d',  # Formato de los números (enteros)
    cmap='Blues',  # Colormap
    xticklabels=['0-No (Pred)', '1-Sí (Pred)'],  # Etiquetas en el eje X
    yticklabels=['0-No (Real)', '1-Sí (Real)']  # Etiquetas en el eje Y
)

# Configurar los títulos y etiquetas
plt.title('Matriz de Confusión - Regresión Logística')
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.show()

"""#Guardar mdelo

"""

import joblib
# Guardar el modelo ganador en un archivo
joblib.dump(best_model_logreg, 'modelo_ganador_logreg.pkl')

print("Modelo guardado como 'modelo_ganador_logreg.pkl'")

"""#Probar modelo ingresando manualmente"""

# Cargar el preprocesador y el modelo
modelo_cargado = joblib.load('modelo_ganador_logreg.pkl')

print("Preprocesador y modelo cargados exitosamente.")

# Crear un nuevo conjunto de datos con las columnas completas y calcular el BMI
nuevos_datos = pd.DataFrame({
    'Genero': ['Male'],  # Cambia estos valores según lo que quieras probar
    'Colesterol': ['1'],
    'Glucosa': ['0'],
    'Fuma': ['0'],
    'Toma_alchol': ['0'],  # Incluye esta columna
    'Actividad_fisica': ['1'],
    'Edad': [47],
    'Altura': [156],  # Altura en centímetros
    'Peso': [50],     # Peso en kilogramos
    'Presion_arterial_sistolica': [100],
    'Presion_arterial_diastolica': [60],
})

# Calcular el BMI (Índice de Masa Corporal)
nuevos_datos['Bmi'] = round(nuevos_datos['Peso'] / ((nuevos_datos['Altura'] / 100) ** 2), 2)


# Transformar los datos con el preprocesador
nuevos_datos_transformados = preprocessor.transform(nuevos_datos)

# Realizar la predicción
prediccion = modelo_cargado.predict(nuevos_datos_transformados)

# Mostrar el resultado
print(f"La predicción para los nuevos datos es: {prediccion}")

# Crear un nuevo conjunto de datos con las columnas completas
nuevos_datos = pd.DataFrame({
    'Genero': ['Male'],  # Cambia estos valores según lo que quieras probar
    'Colesterol': ['1'],
    'Glucosa': ['1'],
    'Fuma': ['0'],
    'Toma_alchol': ['0'],  # Incluye esta columna
    'Actividad_fisica': ['1'],
    'Edad': [42],
    'Altura': [152],
    'Peso': [50],
    'Presion_arterial_sistolica': [110],
    'Presion_arterial_diastolica': [80],
    'Bmi': [round(50 / ((152 / 100) ** 2), 2)]  # Calcular el índice de masa corporal
})

# Transformar los datos con el preprocesador
nuevos_datos_transformados = preprocessor.transform(nuevos_datos)

# Realizar la predicción
prediccion = modelo_cargado.predict(nuevos_datos_transformados)

# Mostrar el resultado
print(f"La predicción para los nuevos datos es: {prediccion}")